{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning On Graphs - Homework 2\n",
    "## Mohammad Bahrami - 9724133"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    [0.3, 0.4, 0.5],\n",
    "    [0.3, 0.4, 0.3],\n",
    "    [0.4, 0.2, 0.2]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigen Values and their respective Eigen Vector:\n",
      "\tEigen Value:  1.000 - Eigen Vector: [-0.66742381 -0.57207755 -0.47673129]\n",
      "\tEigen Value: -0.200 - Eigen Vector: [-7.07106781e-01 -2.75020947e-17  7.07106781e-01]\n",
      "\tEigen Value:  0.100 - Eigen Vector: [ 0.26726124 -0.80178373  0.53452248]\n"
     ]
    }
   ],
   "source": [
    "eivals, eivecs = np.linalg.eig(A)\n",
    "print('Eigen Values and their respective Eigen Vector:')\n",
    "for eival, evec in zip(eivals, eivecs.T):\n",
    "    print(f'\\tEigen Value: {eival: .3f} - Eigen Vector: {evec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigen Values and their respective Normalized Eigen Vector:\n",
      "\tEigen Value:  1.000 - Eigen Vector: [-0.66742381 -0.57207755 -0.47673129]\n",
      "\tEigen Value: -0.200 - Eigen Vector: [-7.07106781e-01 -2.75020947e-17  7.07106781e-01]\n",
      "\tEigen Value:  0.100 - Eigen Vector: [ 0.26726124 -0.80178373  0.53452248]\n"
     ]
    }
   ],
   "source": [
    "print('Eigen Values and their respective Normalized Eigen Vector:')\n",
    "for eival, evec in zip(eivals, eivecs.T / np.linalg.norm(eivecs, axis=0)):\n",
    "    print(f'\\tEigen Value: {eival: .3f} - Eigen Vector: {evec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page Rank Result: \n",
      "[[0.66742381]\n",
      " [0.57207755]\n",
      " [0.47673129]]\n"
     ]
    }
   ],
   "source": [
    "r = np.zeros((A.shape[0], 1)) + 1/A.shape[0]\n",
    "for i in range(20):\n",
    "    r = A @ r\n",
    "r = r / np.linalg.norm(r)\n",
    "print('Page Rank Result: ')\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E\n",
    "\n",
    "We Can see that the result of the page rank is the same as the respective eigen vector of eigen value = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = np.loadtxt('soc-edges.txt')\n",
    "nodes_df = pd.read_csv('soc-nodes.txt')\n",
    "g = nx.Graph()\n",
    "g.add_nodes_from(nodes_df.index.to_numpy())\n",
    "g.add_edges_from(edge_index)\n",
    "degree_vec = pd.DataFrame(dict(g.degree).items()).set_index(0).sort_index().loc[nodes_df['node']].to_numpy()\n",
    "eigen_vec = pd.DataFrame(nx.eigenvector_centrality(g).items()).set_index(0).sort_index().loc[nodes_df['node']].to_numpy()\n",
    "closeness_vec = pd.DataFrame(nx.closeness_centrality(g).items()).set_index(0).sort_index().loc[nodes_df['node']].to_numpy()\n",
    "betweenness_vec = pd.DataFrame(nx.betweenness_centrality(g).items()).set_index(0).sort_index().loc[nodes_df['node']].to_numpy()\n",
    "pagerank_vec = pd.DataFrame(nx.pagerank(g).items()).set_index(0).sort_index().loc[nodes_df['node']].to_numpy()\n",
    "cluster_vec = pd.DataFrame(nx.clustering(g).items()).set_index(0).sort_index().loc[nodes_df['node']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.87\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame(columns=['node', 'degree', 'eigen', 'closeness', 'betweenness', 'clustering', 'pagerank'])\n",
    "data['node'] = nodes_df['node']\n",
    "data['degree'] = degree_vec\n",
    "data['eigen'] = eigen_vec\n",
    "data['closeness'] = closeness_vec\n",
    "data['betweenness'] = betweenness_vec\n",
    "data['clustering'] = cluster_vec\n",
    "data['pagerank'] = pagerank_vec\n",
    "\n",
    "data = data[['node', 'degree', 'closeness', 'betweenness', 'clustering', 'pagerank']]\n",
    "\n",
    "\n",
    "nodes_label = pd.read_csv('./soc-nodes.txt')\n",
    "# adding data labels to data\n",
    "data = pd.merge(data,nodes_label, on = ['node'])\n",
    "\n",
    "# splitting data to training and test sets\n",
    "train = data[data['partition']=='train']\n",
    "test = data[data['partition']=='test']\n",
    "\n",
    "# prepare data for model\n",
    "X_train = train.drop(['node', 'class', 'partition'], axis = 1)\n",
    "X_test = test.drop(['node', 'class', 'partition'], axis = 1)\n",
    "y_train = train['class']\n",
    "y_test = test['class']\n",
    "\n",
    "# training the model\n",
    "model = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make prediction\n",
    "test_prediction = model.predict(X_test)\n",
    "\n",
    "# calculate the accuracy\n",
    "true_predicted = 0\n",
    "for i in range(len(test_prediction)):\n",
    "    if test_prediction[i] == list(y_test)[i]:\n",
    "        true_predicted +=1\n",
    "\n",
    "numberOfTestNodes = len(y_test)\n",
    "\n",
    "print('Accuracy: ', true_predicted/numberOfTestNodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = np.loadtxt('soc-wiki-vote.txt')\n",
    "g = nx.DiGraph()\n",
    "g.add_edges_from(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pagerank(g: nx.DiGraph(), beta: float, threshold: float, max_iterations: int=100):\n",
    "    adj = nx.to_numpy_array(g, nodelist=g.nodes).T\n",
    "    adj[:, np.where(np.sum(adj, axis=0) == 0)] = 1 / adj.shape[0]\n",
    "    adj = adj / np.sum(adj, axis=0, keepdims=1)\n",
    "    r = np.zeros((adj.shape[0], 1)) + 1 / adj.shape[0]\n",
    "    M = beta * adj + (1 - beta) * (np.zeros((adj.shape[0], 1)) + 1 / adj.shape[0])\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        prev_pg = r\n",
    "        r = M @ r\n",
    "        if (np.sum(np.abs(r - prev_pg)) / r.shape[0]) < threshold:\n",
    "            return r, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta:  0.1 - Iterations to Convergence: 3 - Standard Deviation:  0.000188 - Is Identical with nx.pagerank: True\n",
      "Beta:  0.2 - Iterations to Convergence: 4 - Standard Deviation:  0.000377 - Is Identical with nx.pagerank: True\n",
      "Beta:  0.3 - Iterations to Convergence: 5 - Standard Deviation:  0.000568 - Is Identical with nx.pagerank: True\n",
      "Beta:  0.4 - Iterations to Convergence: 6 - Standard Deviation:  0.000763 - Is Identical with nx.pagerank: True\n",
      "Beta:  0.5 - Iterations to Convergence: 7 - Standard Deviation:  0.000962 - Is Identical with nx.pagerank: True\n",
      "Beta:  0.6 - Iterations to Convergence: 8 - Standard Deviation:  0.001169 - Is Identical with nx.pagerank: True\n",
      "Beta:  0.7 - Iterations to Convergence: 10 - Standard Deviation:  0.001384 - Is Identical with nx.pagerank: True\n",
      "Beta:  0.8 - Iterations to Convergence: 12 - Standard Deviation:  0.001614 - Is Identical with nx.pagerank: True\n",
      "Beta:  0.9 - Iterations to Convergence: 15 - Standard Deviation:  0.001864 - Is Identical with nx.pagerank: True\n"
     ]
    }
   ],
   "source": [
    "threshold = 1e-7\n",
    "iden_thresh = 7\n",
    "for beta in np.arange(0.1, 1, 0.1):\n",
    "    pg, i = get_pagerank(g, beta, threshold)\n",
    "    dev = np.std(pg)\n",
    "    iden = np.all(np.round(pg, iden_thresh) == np.round(np.array(list(nx.pagerank(g, alpha=beta, tol=threshold).values())).reshape((-1, 1)), iden_thresh))\n",
    "    print(f'Beta: {beta: .1f} - Iterations to Convergence: {i} - Standard Deviation: {dev: .6f} - Is Identical with nx.pagerank: {iden}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
